{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import firedrake as fd\n",
    "import firedrake_adjoint  # noqa\n",
    "import numpy as np\n",
    "import ufl\n",
    "from torchfire import fd_to_torch\n",
    "import fdm\n",
    "from fecr import evaluate_primal, evaluate_pullback\n",
    "from torch.autograd import Variable\n",
    "import torchviz\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class neural_net(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(neural_net, self).__init__()\n",
    "        self.linear1 = nn.Linear(27, 128)\n",
    "        self.activation1 = nn.Tanh()\n",
    "        self.linear2 = torch.nn.Linear(128, 27)\n",
    "        torch.nn.init.normal_(self.linear2.weight, mean=1.0, std=1.0)\n",
    "        self.activation2 = nn.LeakyReLU()\n",
    "        self.float()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation2(x)\n",
    "        return x\n",
    "\n",
    "def a_function(kappa):\n",
    "    V = fd.FunctionSpace(mesh, \"P\", 1)\n",
    "    x = fd.SpatialCoordinate(mesh)\n",
    "\n",
    "    u = fd.Function(V)\n",
    "    v = fd.TestFunction(V)\n",
    "    bcs = [fd.DirichletBC(V, fd.Constant(2.0), (1,))]\n",
    "\n",
    "    a = (fd.inner( fd.grad(u), fd.grad(v))  - f * v  )* fd.dx\n",
    "\n",
    "    fd.solve( a  == 0, u, bcs=bcs)\n",
    "    return u\n",
    "\n",
    "def u_solution(kappa):\n",
    "    x = fd.SpatialCoordinate(mesh)\n",
    "    F = fd.Function(V)\n",
    "    F.interpolate(fd.sin(x[0] * fd.pi) * fd.sin(2 * x[1] * fd.pi))\n",
    "    return F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 8\n",
    "mesh = fd.UnitSquareMesh(N, 2)\n",
    "V = fd.FunctionSpace(mesh, \"P\", 1)\n",
    "V_kappa = fd.FunctionSpace(mesh, \"DG\", 0)\n",
    "x = fd.SpatialCoordinate(mesh)\n",
    "print(V.dim())\n",
    "print(V_f.dim())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_templates = (fd.Function(V), )\n",
    "F_input = (torch.ones(V.dim(), requires_grad=False),)\n",
    "F = fd_to_torch(F_function, F_templates, \"bob_F\")\n",
    "F_ = F.apply(*F_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = (fd.Function(V_f),)\n",
    "inputs = (torch.ones(V_f.dim(), requires_grad=True),)\n",
    "a = fd_to_torch(a_function, templates, \"bob_a\")\n",
    "a_ = a.apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_L2 = nn.MSELoss()\n",
    "learning_rate = 0.001\n",
    "f_nn = neural_net() #neural_net(N, 68, N)\n",
    "optimizer = torch.optim.Adam(f_nn.parameters(), lr=learning_rate)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1000):\n",
    "    print(f\"Epoch:{epoch}\")\n",
    "    f = f_nn(*inputs)\n",
    "    y = a_(f)\n",
    "\n",
    "    loss = error_L2(y, F_)\n",
    "    grad_x, = torch.autograd.grad(loss, inputs, create_graph=True)\n",
    "    torchviz.make_dot((grad_x, inputs[0] , loss), params={\"grad_x\": grad_x, \"x\": inputs[0], \"out\": loss}).render(\"attached\",format=\"png\")\n",
    "    losses.append(loss)\n",
    "    print(f\"Loss:{loss}\")\n",
    "\n",
    "    # Backpropagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot([loss.detach() for loss in losses][1:])\n",
    "plt.savefig('losses.png')\n",
    "plt.close()\n",
    "print(f.detach().numpy())\n",
    "plt.plot(f.detach().numpy())\n",
    "plt.savefig('f.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
